{
	// Place your snippets for python here. Each snippet is defined under a snippet name and has a prefix, body and 
	// description. The prefix is what is used to trigger the snippet and the body will be expanded and inserted. Possible variables are:
	// $1, $2 for tab stops, $0 for the final cursor position, and ${1:label}, ${2:another} for placeholders. Placeholders with the 
	// same ids are connected.
	// Example:
	// "Print to console": {
	// 	"prefix": "log",
	// 	"body": [
	// 		"console.log('$1');",
	// 		"$2"
	// 	],
	// 	"description": "Log output to console"
	// }
	"main": {
		"prefix": "main",
		"body": [
			"if __name__ == '__main__':",
			"    ${1:pass}"
		],
		"description": "main"
	},
    "main_main": {
		"prefix": "main_main",
		"body": [
            "def main():",
			"    ${1:pass}",
            "",
			"if __name__ == '__main__':",
			"    main()"
		],
		"description": "main"
	},
    "import numpy as np": {
		"prefix": "import numpy as np",
		"body": [
			"import numpy as np",
		],
		"description": "import numpy as np"
	},
	"with open(filepath, 'rb') as f:": {
		"prefix": "with open(filepath, 'rb') as f:",
		"body": [
			"with open(filepath, 'rb') as f:",
			"    f",
		],
		"description": "with open(filepath, 'rb') as f:"
	},
	"datetime.now().strftime('%Y%m%d_%H%M%S')": {
		"prefix": "datetime.now().strftime('%Y%m%d_%H%M%S')",
		"body": [
			"datetime.now().strftime('%Y%m%d_%H%M%S')",
		],
		"description": "datetime.now().strftime('%Y%m%d_%H%M%S')"
    },
	"from glob import glob": {
		"prefix": "from glob import glob",
		"body": [
			"from glob import glob",
		],
		"description": "from glob import glob"
	},
	"glob_dir": {
		"prefix": "sorted glob(dir_name+os.sep+'*')",
		"body": [
			"sorted(glob(dir_name+os.sep+'*'))",
		],
		"description": "glob_dir"
	},
	"glob recursive": {
		"prefix": "sorted glob(dir_name+os.sep+'*/*', recursive=True)",
		"body": [
			"sorted(glob(dir_name+os.sep+'*/*', recursive=True))",
		],
		"description": "glob recursive"
	},
	"sorted glob_dir": {
		"prefix": "sorted(glob(dir_name+os.sep+'*'))",
		"body": [
			"sorted(glob(dir_name+os.sep+'*'))",
		],
		"description": "sorted glob_dir"
	},
	"lgb": {
        "prefix": [
            "lgb",
            "import lightgbm as lgb"
        ],
        "body": "import lightgbm as lgb",
        "description": "Import LightGBM"
    },
    "np": {
        "prefix": [
            "np",
            "import numpy as np"
        ],
        "body": "import numpy as np",
        "description": "Import Numpy"
    },
    "pd": {
        "prefix": [
            "pd",
            "import pandas as pd"
        ],
        "body": "import pandas as pd",
        "description": "Import Pandas"
    },
    "plt": {
        "prefix": [
            "plt",
            "import matplotlib.pyplot as plt",
            "from matplotlib import ..."
        ],
        "body": "from matplotlib import pyplot as plt",
        "description": "Import Matplotlib"
    },
    "sns": {
        "prefix": [
            "sns",
            "import seaborn as sns"
        ],
        "body": "import seaborn as sns",
        "description": "Import seaborn"
    },
    "joblib.dump": {
        "prefix": [
            "joblib.dump",
            "from joblib import dump"
        ],
        "body": "from joblib import dump",
        "description": "Import `dump` in Joblib"
    },
    "joblib.load": {
        "prefix": [
            "joblib.load",
            "from joblib import load"
        ],
        "body": "from joblib import load",
        "description": "Import `load` in Joblib"
    },
    "sklearn.compose.make_column_transformer": {
        "prefix": [
            "sklearn.compose.make_column_transformer",
            "from sklearn.compose import ..."
        ],
        "body": "from sklearn.compose import make_column_transformer",
        "description": "Import `make_column_transformer` in scikit-learn"
    },
    "sklearn.datasets.load_*": {
        "prefix": [
            "sklearn.datasets.load_*",
            "from sklearn.datasets import ..."
        ],
        "body": "from sklearn.datasets import ${1:load_iris}",
        "description": "Import a function that loads a dataset"
    },
    "sklearn.pipeline.make_pipeline": {
        "prefix": [
            "sklearn.pipeline.make_pipeline",
            "from sklearn.pipeline import ..."
        ],
        "body": "from sklearn.pipeline import make_pipeline",
        "description": "Import `make_pipeline` in scikit-learn"
    },
    "logger = ...": {
        "prefix": "logger = ...",
        "body": "logger = logging.getLogger(${1:__name__})",
        "description": "Get a logger"
    },
    "dtrain = ...": {
        "prefix": "dtrain = ...",
        "body": "dtrain = lgb.Dataset(${1:X}, label=${2:y})",
        "description": "Create a LightGBM dataset instance"
    },
    "booster = ...": {
        "prefix": "booster = ...",
        "body": [
            "booster = lgb.train(",
            "\t${1:params},",
            "\t${2:dtrain},",
            "\t${3:# **kwargs}",
            ")"
        ],
        "description": "Train a LightGBM booster"
    },
    "ax = ...": {
        "prefix": "ax = ...",
        "body": [
            "ax = lgb.plot_importance(",
            "\t${1:booster},",
            "\t${2:# **kwargs}",
            ")"
        ],
        "description": "Plot feature importances"
    },
    "f, ax = ...": {
        "prefix": "f, ax = ...",
        "body": "f, ax = plt.subplots(figsize=${1:(8, 6)})",
        "description": "Create a figure and a set of subplots"
    },
    "df = ...": {
        "prefix": "df = ...",
        "body": [
            "df = pd.read_csv(",
            "\t${1:filepath_or_buffer},",
            "\t${2:# **kwargs}",
            ")"
        ],
        "description": "Read a csv file into a Pandas dataFrame"
    },
    "df = pd.read_csv(fn, encoding=\"shift-jis\")": {
        "prefix": "pd.read_csv(fn, encoding=",
        "body": [
            "df = pd.read_csv(",
            "\t${1:filepath_or_buffer},",
            "\t${2:# **kwargs}",
            "\tencoding=\"shift-jis\"",
            ")"
        ],
        "description": "Read a csv file into a Pandas dataFrame"
    },
    "description = ...": {
        "prefix": "description = ...",
        "body": "description = ${1:df}.describe(include=${2:\"all\"})",
        "description": "Create a Pandas dataframe description"
    },
    "with pd.option_context(...": {
        "prefix": "with pd.option_context(...",
        "body": [
            "with.pd.option_context(",
            "\t\"display.max_rows\",",
            "\t${1:None},",
            "\t\"display.max_columns\",",
            "\t${2:None},",
            "):",
            "\tdisplay(${3:pass})"
        ],
        "description": "Set temporarily Pandas options"
    },
    "X, y = ...": {
        "prefix": "X, y = ...",
        "body": "X, y = ${1:load_iris}(return_X_y=True)",
        "description": "Load and return the dataset"
    },
    "from sklearn.model_selection import train_test_split": {
        "prefix": "from sklearn.model_selection import train_test_split",
        "body": "from sklearn.model_selection import train_test_split",
        "description": "from sklearn.model_selection import train_test_split"
    },
    "X_train, X_test, ...": {
        "prefix": "X_train, X_test, ...",
        "body": [
            "X_train, X_test, y_train, y_test = train_test_split(",
            "\tX,",
            "\ty,",
            "\trandom_state=${1:0},",
            "\tshuffle=${2:True},",
            ")"
        ],
        "description": "Split arrays into train and test subsets"
    },
    "estimator = BaseEstimator(...": {
        "prefix": "estimator = BaseEstimator(...",
        "body": [
            "estimator = ${1:BaseEstimator}(",
            "\t${2:# **params}",
            ")"
        ],
        "description": "Create an scikit-learn estimator instance"
    },
    "estimator = make_pipeline(...": {
        "prefix": "estimator = make_pipeline(...",
        "body": [
            "estimator = make_pipeline(",
            "\t${1:estimator},",
            "\t${2:# *steps}",
            ")"
        ],
        "description": "Create a scikit-learn pipeline instance"
    },
    "estimator = make_column_transformer(...": {
        "prefix": "estimator = make_column_transformer(...",
        "body": [
            "estimator = make_column_transformer(",
            "\t(${1:estimator}, ${2:columns}),",
            "\t${3:# *transformers}",
            ")"
        ],
        "description": "Create a scikit-learn column transformer instance"
    },
    "estimator.fit(...": {
        "prefix": "estimator.fit(...",
        "body": [
            "${1:estimator}.fit(",
            "\t${2:X},",
            "\ty=${3:y},",
            "\t${4:# **fit_params}",
            ")"
        ],
        "description": "Fit the estimator according to the given training data"
    },
    "dump(...": {
        "prefix": "dump(...",
        "body": "dump(${1:estimator}, ${2:filename}, compress=${3:0})",
        "description": "Save the estimator"
    },
    "estimator = load(...": {
        "prefix": "estimator = load(...",
        "body": "estimator = load(${1:filename})",
        "description": "Load the estimator"
    },
    "y_pred = ...": {
        "prefix": "y_pred = ...",
        "body": "y_pred = ${1:estimator}.predict(${2:X})",
        "description": "Predict using the fitted model"
    },
    "X = ...": {
        "prefix": "X = ...",
        "body": "X = ${1:estimator}.transform(${2:X})",
        "description": "Transform the data"
	},
	"MyClass": {
		"prefix": "class",
		"body": [
            "class MyClass:",
			"    def __init__(self):",
			"        self.name = ''",
		],
		"description": "class"
	},
	"argparse": {
		"prefix": "argparse",
		"body": [
            "parser = argparse.ArgumentParser(description='このプログラムの説明', formatter_class=argparse.ArgumentDefaultsHelpFormatter, fromfile_prefix_chars='@')",
			"parser.add_argument('--filename', default=\"\", help='ファイル名.必ず指定する引数にする場合--filename→filenameとする.')",
            "parser.add_argument('--input_dir', default=\".\", help='入力ディレクトリ.必ず指定する引数にする場合--input_dir→input_dirとする.')",
			"parser.add_argument('--seed', type=int,default=4321, help='random seed')",
			"parser.add_argument('-a', '--arg4', type=float)",
			"parser.add_argument('--arg_if_set_true', action='store_true', help='セットすると変数にTrueがセットされる')",
			"parser.add_argument('--arg_if_set_false', action='store_false', help='セットすると変数にFalseがセットされる')",
			"parser.add_argument('-n', '--narg', nargs='*', default=[])",
			"args = parser.parse_args()",
			"pprint(args.__dict__)",
		],
		"description": "argparse"
	},
	"OrderedDict": {
		"prefix": "from collections import OrderedDict",
		"body": [
			"from collections import OrderedDict",
		],
		"description": "OrderedDict"
    },
	"tqdm": {
		"prefix": "tqdm",
		"body": [
			"for _ in tqdm(_s):",
            "    print(_)",
		],
		"description": "tqdm"
    },
	"enumerate_tqdm": {
		"prefix": "enumerate_tqdm",
		"body": [
			"for index, _ in enumerate(tqdm(_s)):",
            "    print(index, _)",
		],
		"description": "enumerate_tqdm"
    },
	"from tqdm import tqdm": {
		"prefix": "from tqdm import tqdm",
		"body": [
			"from tqdm import tqdm",
		],
		"description": "from tqdm import tqdm"
    },
	"enumerate": {
		"prefix": "enumerate",
		"body": [
            "for index, _ in enumerate(_s):",
            "    print(index, _)",
		],
		"description": "enumerate"
    },
    "enumerate_zip": {
		"prefix": "enumerate_zip",
		"body": [
            "for index, (_1, _2) in enumerate(zip(_1s, _2s)):",
            "    print(index, _1, _2)",
		],
		"description": "enumerate_zip"
    },
	"tqdm_zip": {
		"prefix": "tqdm_zip",
		"body": [
            "for (_1, _2) in tqdm(zip(_1s, _2s)):",
            "    print(_1, _2)"
		],
		"description": "tqdm_zip"
    },
	"enumerate_tqdm_zip": {
		"prefix": "enumerate_tqdm_zip",
		"body": [
            "for index, (_1, _2) in enumerate(tqdm(zip(_1s, _2s))):",
            "    print(index, _1, _2)",
		],
		"description": "enumerate_tqdm_zip"
    },
	"json load": {
		"prefix": "json load",
		"body": [
            "with open('json.json') as f:",
            "   _ = json.load(f)"
        ],
		"description": "json load"
    },
	"json dump": {
		"prefix": "json dump",
		"body": [
            "with open('_.json', 'w') as f:",
            "   json.dump(d, f, indent=4)"
        ],
		"description": "json dump"
	},
	"pathlib mkdir": {
		"prefix": "pathlib mkdir",
		"body": [
            "output_dir=Path('_')",
            "if output_dir.exists():",
            "    shutil.rmtree(output_dir.name)",
            "output_dir.mkdir(parents=True, exist_ok=True)"
        ],
		"description": "pathlib mkdir"
    },
	"pickle load": {
		"prefix": "pickle load",
		"body": [
        "with open('_.pkl', 'rb') as f:",
        "    _ = pickle.load(f)"
        ],
		"description": "pickle load"
    },
    "elappsed time": {
		"prefix": "elappsed time",
		"body": [
            "start_time = time()",
            "elapsed_time = time() - start_time",
            "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"       ],
		"description": "elappsed time"
    },
    "np where": {
		"prefix": "np where",
		"body": [
            "list(zip(*np.where(a < 4)))"
        ],
		"description": "np where 2dim"
    },
    "random sample": {
		"prefix": "random sample",
		"body": [
            "__ = random.sample(_, len(_))"
        ],
		"description": "random sample"
    },
    "judge str None": {
        "prefix":"judge str None",
        "body": [
             "string = ''",
             "if not string:",
             "    print('NULL')",
             "else:",
             "    print('文字あり')",
        ],
        "description":"snippet description",
    },
    "pathlib mkdir 2dir": {
		"prefix": "pathlib mkdir 2dir",
		"body": [
            "output_root_dir=\"the_root_dir\"",
            "output__dir=Path(output_root_dir) / \"the_dir_1\"",
            "output___dir=Path(output_root_dir) / \"the_dir_2\"",
            "",
            "if output__dir.exists():",
            "    shutil.rmtree(str(output__dir))",
            "output__dir.mkdir(parents=True, exist_ok=True)",
            "",
            "if output___dir.exists():",
            "    shutil.rmtree(str(output___dir))",
            "output___dir.mkdir(parents=True, exist_ok=True)"
        ],
        "description": "pathlib mkdir 2dir"
    },
    "pathlib mkdir 2dir 2": {
		"prefix": "pathlib mkdir 2dir 2",
		"body": [
            "output_root_dir=Path(\"output_root_dir\")",
            "if output_root_dir.exists():",
            "    shutil.rmtree(output_root_dir)",
            "",
            "output_dir1=output_root_dir / \"_dir1\"",
            "output_dir2=output_root_dir / \"_dir2\"",
            "",
            "output_dir1.mkdir(parents=True, exist_ok=True)",   
            "output_dir2.mkdir(parents=True, exist_ok=True)"
        ],
        "description": "pathlib mkdir 2dir 2"
    },
    "0 fill str format": {
        "prefix": "0 fill str format",
        "body": [
        "num=3",
        "str_value='{:03}'.format(num)",
        ],
        "description": "0 fill str format"
    },
    "read line": {
        "prefix":"read line",
        "body": [
                "with open(args.filepath, 'r') as f:",
                "    lines = f.readlines()",
                "    lines=lines.splitlines()",
                "",
                "    for line in lines:",
                "        print(line)",
        ],
        "description":"read line from file",
    },
    "contour_bin": {
        "prefix":"contour_bin",
        "body": [
             "    bin_image_copy = bin_image.copy()",
             "    contours, hierarchy = cv2.findContours(bin_image_copy, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)",
             "",
             "    output_image=np.zeros_like(bin_image_copy)",
             "    for contour in contours:",
             "        area=cv2.contourArea(contour)",
             "        output_image=cv2.drawContours(output_image, [contour], 0, 255, -1)",
             "",
             "    output_image=cv2.drawContours(output_image, contours, -1, 255, -1)",

        ],
        "description":"snippet description",
    },
    "Logger Class": {
    "prefix":"Logger Class",
    "body": [
            "class Logger Class:",
            "    def __init__(self):",
            "        self.config = {}",
            "        self.nclass = 0",
            "        self.model = None",
            "        self.model_id_info=\"\"",
            "",
            "        self.logger = None",
            "",
            "        self.cmap = np.array([",
            "                   [  0,   0,   0],",
            "                   [128,   0,   0],",
            "                   [  0, 128,   0],",
            "                   [128, 128,   0],",
            "                   [  0,   0, 128],",
            "                   [128,   0, 128],",
            "                   [  0, 128, 128],",
            "                   [128, 128, 128],",
            "                   [ 64,   0,   0],",
            "                   [192,   0,   0],",
            "                   [ 64, 128,   0],",
            "                   [192, 128,   0],",
            "                   [ 64,   0, 128],",
            "                   [192,   0, 128],",
            "                   [ 64, 128, 128],",
            "                   [192, 128, 128],",
            "                   [  0,  64,   0],",
            "                   [128,  64,   0],",
            "                   [  0, 192,   0],",
            "                   [128, 192,   0],",
            "                   [  0,  64, 128]])",
            "",
            "    \"\"\"",
            "    def __del__(self):",
            "#        self.logger.debug(\"PySeg.__del__\")",
            "",
            "        # 念のため古いloggerが持つハンドラを削除する",
            "        for h in self.logger.handlers:",
            "            self.logger.removeHandler(h)",
            "    \"\"\"",
            "",
            "    def setup(self, config_filename):",
            "        try:",
            "            start_time = time()",
            "",
            "            # ハンドラが残っていたら保持している内容をフラッシュさせる。",
            "            # こうすることで新たなロガーを構築する際にログファイルの保持をやめさせることができる（ただしこの使い方は非推奨）",
            "            logging.shutdown()",
            "",
            "            # ロガーを構築する",
            "            self.logger = getLogger('pyseg_'+datetime.now().strftime('%Y%m%d%H%M%S'))",
            "",
            "            self.logger.setLevel(DEBUG)",
            "            formatter = Formatter(\"[%(asctime)s] [%(process)d] [%(name)s] [%(levelname)s] %(message)s\")",
            "",
            "            with open(config_filename) as f:",
            "                self.config = json.load(f)",
            "",
            "            # handler構築",
            "            handler = StreamHandler()",
            "",
            "            # stdout",
            "            handler.setLevel(self.config[\"stdout_loglevel\"])",
            "            handler.setFormatter(formatter)",
            "            self.logger.addHandler(handler)",
            "            ",
            "            \"\"\"",
            "            # 古いログファイルを退避する",
            "            log_filepath=self.config[\"log_filepath\"]",
            "            existing_log_filepaths=glob(log_filepath+\"*\")",
            "            ",
            "            if len(existing_log_filepaths) > 0:",
            "                dir_name = os.path.dirname(os.path.abspath(existing_log_filepaths[0]))",
            "                evacuate_dir=dir_name+os.sep+\"old_log\"+os.sep+\"bkup\"+datetime.now().strftime('%Y%m%d%H%M%S')",
            "                os.makedirs(evacuate_dir)",
            "                print(existing_log_filepaths)",
            "                for filepath in existing_log_filepaths:",
            "                    shutil.move(dir_name+os.sep+filepath, evacuate_dir+os.sep+filepath)",
            "            \"\"\"",
            "",
            "            # file",
            "            handler = handlers.RotatingFileHandler(filename = self.config[\"log_filepath\"],",
            "                                                   maxBytes = self.config[\"logfile_max_bytes\"],",
            "                                                   backupCount = self.config[\"backup_count\"])",
            "            handler.setLevel(self.config[\"file_loglevel\"])",
            "            handler.setFormatter(formatter)",
            "            self.logger.addHandler(handler)",
            "",
            "            self.logger.info(\"Loading config file and setting up logger are done.\")",
            "",
            "            self.logger.info(\"------start logging------\")",
            "",
            "            # 情報を残す",
            "            self.logger.info(\"config_filename:\"+pformat(self.config))",
            "            self.logger.info(\"numpy ver:\"+str(np.__version__))",
            "            self.logger.info(\"torch ver:\"+str(torch.__version__))",
            "            self.logger.info(\"cloudpickle ver:\"+str(cloudpickle.__version__))",
            "            self.logger.info(\"cv2 ver:\"+str(cv2.__version__))",
            "            self.logger.info(\"imageio ver:\"+str(imageio.__version__))",
            "",
            "            self.__get_model(self.config[\"model_filepath\"])",
            "",
            "            wall_time = time() - start_time",
            "",
            "            self.logger.info(\"setup() is done.wall_time:\"+str(wall_time) +\"(sec)\")",
            "",
            "        except Exception as err:",
            "            self.logger.exception(err)",
            "            raise err",
        ],
        "description":"Logger Class",
    },
    "from pathlib import Path": {
    "prefix": "from pathlib import Path",
    "body": [
        "from pathlib import Path",
    ],
    "description": "from pathlib import Path"
    },
    "joblib paralell": {
        "prefix":"joblib paralell",
        "body": [
            "from math import modf",
            "from joblib import Parallel, delayed",
            "",
            "def func(a):",
            "   return modf(a)",
            "",
            "results = Parallel(n_jobs=-1, verbose=10)(delayed(func)(i/2.) for i in range(10))",
            "decimals, integers = zip(*results)",
            "",
            "for decimal, integer in zip(decimals,integers):",
            "   print(decimal, integer)",
            "",
        ],
        "description":"snippet description",
	},
    "joblib parallel 2 args": {
        "prefix":"joblib parallel 2 args",
        "body": [
             "from joblib import Parallel, delayed",
             "",
             "def func(a, b):",
             "    return a * b",
             "",
             "a_list=list(range(10))",
             "b_list=list(range(10))",
             "",
             "results = Parallel(n_jobs=-1, verbose=10)([delayed(func)(a, b) for a, b in zip(a_list, b_list)])",
             "",
             "for result in results:",
             "    print(result)",
             "",
        ],
        "description":"snippet description",
    },
    "import pdb;pdb.set_trace()": {
        "prefix": "import pdb;pdb.set_trace()",
        "body": [
            "import pdb;pdb.set_trace()",
        ],
        "description": "import pdb;pdb.set_trace()"
    },
    "train val test": {
        "prefix": "train val test",
        "body": [
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, shuffle=True)",
            "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1, shuffle=True)",
        ],
        "description": "train val test"
    },
	"from pprint import pprint": {
		"prefix": "from pprint import pprint",
		"body": [
			"from pprint import pprint",
		],
		"description": "from pprint import pprint"
    },
	"threshold": {
		"prefix": "thresold",
		"body": [
			"image = cv2.imread('gradient.png',0)",
            "ret,thresh1 = cv2.threshold(image,127,255,cv2.THRESH_BINARY)",
		],
		"description": "thresold"
    },
	"replace_ext": {
		"prefix": "replace_ext",
		"body": [
            "def replace_ext(filename, ext):",
            "   '''",
            "   filename:置き換え対象",
            "   ext:拡張子(.tifなど.付きで指定する)",
            "   '''",
            "   return os.path.splitext(filename)[0]+ext"
            ],
            "description": "replace_ext"
        },    
}